{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-04T19:27:38.348535Z",
     "start_time": "2025-04-04T19:27:38.346568Z"
    }
   },
   "source": [
    "# Load all the required packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import openmeteo_requests\n",
    "import requests_cache\n",
    "from retry_requests import retry\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import seaborn as sns"
   ],
   "outputs": [],
   "execution_count": 109
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Call the API, fetch the required data and create the dataframe",
   "id": "1cd7991a838d2788"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T19:27:38.450167Z",
     "start_time": "2025-04-04T19:27:38.447685Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a data directory call Data for our data\n",
    "os.makedirs(\"Data\", exist_ok=True)\n",
    "print(f\"Folder Data created successfully!\")"
   ],
   "id": "9a6a7ac6612b61b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder Data created successfully!\n"
     ]
    }
   ],
   "execution_count": 110
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T19:27:38.465123Z",
     "start_time": "2025-04-04T19:27:38.463457Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Declare the latitude and longitude for both cities\n",
    "cities = {\"Zurich\": {'loc': [\"47.3769\", \"8.5417\"]},\n",
    "\t\t  \"Toronto\": {'loc': [\"43.6532\", \"79.3832\"]}}"
   ],
   "id": "b2144baa0a11183f",
   "outputs": [],
   "execution_count": 111
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T19:27:38.471047Z",
     "start_time": "2025-04-04T19:27:38.467896Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Setup the Open-Meteo API client with cache and retry on error\n",
    "cache_session = requests_cache.CachedSession('.cache', expire_after = -1)\n",
    "retry_session = retry(cache_session, retries = 5, backoff_factor = 0.2)\n",
    "openmeteo = openmeteo_requests.Client(session = retry_session)"
   ],
   "id": "11d3f66e4f425ffd",
   "outputs": [],
   "execution_count": 112
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T19:27:38.493456Z",
     "start_time": "2025-04-04T19:27:38.490826Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def call_API(city, openmeteo):\n",
    "    # Set the API call parameters\n",
    "    url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "    params = {\n",
    "        \"latitude\": cities[city]['loc'][0],\n",
    "        \"longitude\": cities[city]['loc'][1],\n",
    "        \"start_date\": \"1940-01-01\",\n",
    "        \"end_date\": \"2024-12-31\",\n",
    "        \"daily\": [\"weather_code\", \"temperature_2m_max\", \"temperature_2m_min\", \"temperature_2m_mean\",\n",
    "                \"apparent_temperature_max\", \"apparent_temperature_min\", \"apparent_temperature_mean\", \"sunrise\",\n",
    "                \"sunset\", \"daylight_duration\", \"sunshine_duration\", \"precipitation_sum\", \"rain_sum\", \"snowfall_sum\",\n",
    "                \"precipitation_hours\", \"wind_speed_10m_max\", \"wind_gusts_10m_max\", \"wind_direction_10m_dominant\",\n",
    "                \"shortwave_radiation_sum\", \"et0_fao_evapotranspiration\"],\n",
    "        \"timezone\": cities[city].get('timezone', \"Europe/Berlin\"),\n",
    "        \"temperature_unit\": \"celsius\",\n",
    "        \"wind_speed_unit\": \"kmh\",\n",
    "        \"precipitation_unit\": \"mm\"\n",
    "    }\n",
    "    responses = openmeteo.weather_api(url, params=params)\n",
    "\n",
    "    # Print the first part of the API response to validate the call data is valid\n",
    "    response = responses[0]\n",
    "    print(f\"Coordinates {response.Latitude()}°N {response.Longitude()}°E\")\n",
    "    print(f\"Elevation {response.Elevation()} m asl\")\n",
    "    print(f\"Timezone {response.Timezone()} {response.TimezoneAbbreviation()}\")\n",
    "    print(f\"Timezone difference to GMT+0 {response.UtcOffsetSeconds()} s\")\n",
    "   \n",
    "    return response"
   ],
   "id": "114806bee6814c52",
   "outputs": [],
   "execution_count": 113
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In the create_dataframe function we validate the data types as we receive the data, we also change the date format into a readable format and into a format that useful for our project as we don't need anything but the date. This save us from performing these tasks later on when we clean our data.",
   "id": "76d20c9a60cd18f7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T19:27:38.516839Z",
     "start_time": "2025-04-04T19:27:38.511847Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_dataframe(response):\n",
    "\t# Process data and validate variable types\n",
    "\tdaily = response.Daily()\n",
    "\tdaily_weather_code = daily.Variables(0).ValuesAsNumpy()\n",
    "\tdaily_temperature_2m_max = daily.Variables(1).ValuesAsNumpy()\n",
    "\tdaily_temperature_2m_min = daily.Variables(2).ValuesAsNumpy()\n",
    "\tdaily_temperature_2m_mean = daily.Variables(3).ValuesAsNumpy()\n",
    "\tdaily_apparent_temperature_max = daily.Variables(4).ValuesAsNumpy()\n",
    "\tdaily_apparent_temperature_min = daily.Variables(5).ValuesAsNumpy()\n",
    "\tdaily_apparent_temperature_mean = daily.Variables(6).ValuesAsNumpy()\n",
    "\tdaily_sunrise = daily.Variables(7).ValuesAsNumpy()\n",
    "\tdaily_sunset = daily.Variables(8).ValuesAsNumpy()\n",
    "\tdaily_daylight_duration = daily.Variables(9).ValuesAsNumpy()\n",
    "\tdaily_sunshine_duration = daily.Variables(10).ValuesAsNumpy()\n",
    "\tdaily_precipitation_sum = daily.Variables(11).ValuesAsNumpy()\n",
    "\tdaily_rain_sum = daily.Variables(12).ValuesAsNumpy()\n",
    "\tdaily_snowfall_sum = daily.Variables(13).ValuesAsNumpy()\n",
    "\tdaily_precipitation_hours = daily.Variables(14).ValuesAsNumpy()\n",
    "\tdaily_wind_speed_10m_max = daily.Variables(15).ValuesAsNumpy()\n",
    "\tdaily_wind_gusts_10m_max = daily.Variables(16).ValuesAsNumpy()\n",
    "\tdaily_wind_direction_10m_dominant = daily.Variables(17).ValuesAsNumpy()\n",
    "\tdaily_shortwave_radiation_sum = daily.Variables(18).ValuesAsNumpy()\n",
    "\tdaily_et0_fao_evapotranspiration = daily.Variables(19).ValuesAsNumpy()\n",
    "\t\n",
    "\t# Format the date variable to readable format\n",
    "\tdaily_data = {\"date\": pd.date_range(\n",
    "\t\tstart = pd.to_datetime(daily.Time(), unit = \"s\", utc = True),\n",
    "\t\tend = pd.to_datetime(daily.TimeEnd(), unit = \"s\", utc = True),\n",
    "\t\tfreq = pd.Timedelta(seconds = daily.Interval()),\n",
    "\t\tinclusive = \"left\"\n",
    "\t\t).strftime('%Y/%m/%d')\n",
    "\t}\n",
    "\t\n",
    "\t# Create the pandas dataframe\n",
    "\tdaily_data[\"weather_code\"] = daily_weather_code\n",
    "\tdaily_data[\"temperature_2m_max\"] = daily_temperature_2m_max\n",
    "\tdaily_data[\"temperature_2m_min\"] = daily_temperature_2m_min\n",
    "\tdaily_data[\"temperature_2m_mean\"] = daily_temperature_2m_mean\n",
    "\tdaily_data[\"apparent_temperature_max\"] = daily_apparent_temperature_max\n",
    "\tdaily_data[\"apparent_temperature_min\"] = daily_apparent_temperature_min\n",
    "\tdaily_data[\"apparent_temperature_mean\"] = daily_apparent_temperature_mean\n",
    "\tdaily_data[\"sunrise\"] = daily_sunrise\n",
    "\tdaily_data[\"sunset\"] = daily_sunset\n",
    "\tdaily_data[\"daylight_duration\"] = daily_daylight_duration\n",
    "\tdaily_data[\"sunshine_duration\"] = daily_sunshine_duration\n",
    "\tdaily_data[\"precipitation_sum\"] = daily_precipitation_sum\n",
    "\tdaily_data[\"rain_sum\"] = daily_rain_sum\n",
    "\tdaily_data[\"snowfall_sum\"] = daily_snowfall_sum\n",
    "\tdaily_data[\"precipitation_hours\"] = daily_precipitation_hours\n",
    "\tdaily_data[\"wind_speed_10m_max\"] = daily_wind_speed_10m_max\n",
    "\tdaily_data[\"wind_gusts_10m_max\"] = daily_wind_gusts_10m_max\n",
    "\tdaily_data[\"wind_direction_10m_dominant\"] = daily_wind_direction_10m_dominant\n",
    "\tdaily_data[\"shortwave_radiation_sum\"] = daily_shortwave_radiation_sum\n",
    "\tdaily_data[\"et0_fao_evapotranspiration\"] = daily_et0_fao_evapotranspiration\n",
    "\t\n",
    "\t# Make a dataframe from the dictionary\n",
    "\tdaily_dataframe = pd.DataFrame(data = daily_data)\n",
    "\t\n",
    "\treturn daily_dataframe"
   ],
   "id": "373cfc0fc00685a2",
   "outputs": [],
   "execution_count": 114
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T19:27:38.527515Z",
     "start_time": "2025-04-04T19:27:38.525305Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def save_df(data, city):\n",
    "\t# Save the dataframe as csv file\n",
    "\tdata.to_csv(f\"Data/{city}.csv\", index = False)\n",
    "\tprint(f\"Saved data for '{city}' successfully!\")"
   ],
   "id": "6365bdfece8b966e",
   "outputs": [],
   "execution_count": 115
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T19:27:38.536748Z",
     "start_time": "2025-04-04T19:27:38.534804Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def combine_dataframes():\n",
    "\t# Create a single dataframe from the 2 datasets\n",
    "\t# Load the 2 datasets\n",
    "\tdf1 = pd.read_csv(\"Data/Zurich.csv\")\n",
    "\tdf2 = pd.read_csv(\"Data/Toronto.csv\")\n",
    "\t\n",
    "\t# Add a column to contains the city name\n",
    "\tdf1['City'] = 'Zurich'\n",
    "\tdf2['City'] = 'Toronto'\n",
    "\t\n",
    "\t# Concatenate the 2 dataframes\n",
    "\tstart_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\t\n",
    "\t# Write combined dataframes to csv file\n",
    "\tstart_df.to_csv(\"Data/start.csv\", index = False)"
   ],
   "id": "c3f08b8341e6dafd",
   "outputs": [],
   "execution_count": 116
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T19:29:39.019703Z",
     "start_time": "2025-04-04T19:27:38.554775Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Call the API and save the as csv files\n",
    "# Saving as csv files to limit the amount of calls to data provider\n",
    "count = 0\n",
    "for city in cities:\n",
    "    response = call_API(city, openmeteo)\n",
    "    data = create_dataframe(response)\n",
    "    save_df(data, city)\n",
    "    print('\\n')\n",
    "\n",
    "    # Delay the 2nd API call for 2 minutes to not violate limits on API calls\n",
    "    if count < 1:\n",
    "        print(\"\\n Taking a 2 minute break, please be patient........ \")\n",
    "        time.sleep(120)\n",
    "    count += 1"
   ],
   "id": "36ca805cf6b20cc3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinates 47.34621810913086°N 8.54337215423584°E\n",
      "Elevation 409.0 m asl\n",
      "Timezone b'Europe/Berlin' b'GMT+2'\n",
      "Timezone difference to GMT+0 7200 s\n",
      "Saved data for 'Zurich' successfully!\n",
      "\n",
      "\n",
      "\n",
      " Taking a 2 minute break, please be patient........ \n"
     ]
    },
    {
     "ename": "OpenMeteoRequestsError",
     "evalue": "{'reason': 'Daily API request limit exceeded. Please try again tomorrow.', 'error': True}",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOpenMeteoRequestsError\u001B[0m                    Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[117], line 5\u001B[0m\n\u001B[1;32m      3\u001B[0m count \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m city \u001B[38;5;129;01min\u001B[39;00m cities:\n\u001B[0;32m----> 5\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mcall_API\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcity\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopenmeteo\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      6\u001B[0m     data \u001B[38;5;241m=\u001B[39m create_dataframe(response)\n\u001B[1;32m      7\u001B[0m     save_df(data, city)\n",
      "Cell \u001B[0;32mIn[113], line 19\u001B[0m, in \u001B[0;36mcall_API\u001B[0;34m(city, openmeteo)\u001B[0m\n\u001B[1;32m      3\u001B[0m url \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps://archive-api.open-meteo.com/v1/archive\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      4\u001B[0m params \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m      5\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlatitude\u001B[39m\u001B[38;5;124m\"\u001B[39m: cities[city][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mloc\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;241m0\u001B[39m],\n\u001B[1;32m      6\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlongitude\u001B[39m\u001B[38;5;124m\"\u001B[39m: cities[city][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mloc\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;241m1\u001B[39m],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     17\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprecipitation_unit\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmm\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     18\u001B[0m }\n\u001B[0;32m---> 19\u001B[0m responses \u001B[38;5;241m=\u001B[39m \u001B[43mopenmeteo\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweather_api\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;66;03m# Print the first part of the API response to validate the call data is valid\u001B[39;00m\n\u001B[1;32m     22\u001B[0m response \u001B[38;5;241m=\u001B[39m responses[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[0;32m~/PycharmProjects/python3.12.3/.venv/lib/python3.12/site-packages/openmeteo_requests/Client.py:54\u001B[0m, in \u001B[0;36mClient.weather_api\u001B[0;34m(self, url, params, method, verify, **kwargs)\u001B[0m\n\u001B[1;32m     50\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mweather_api\u001B[39m(\n\u001B[1;32m     51\u001B[0m     \u001B[38;5;28mself\u001B[39m, url: \u001B[38;5;28mstr\u001B[39m, params: \u001B[38;5;28many\u001B[39m, method: \u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGET\u001B[39m\u001B[38;5;124m\"\u001B[39m, verify: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m|\u001B[39m \u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[1;32m     52\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mlist\u001B[39m[WeatherApiResponse]:\n\u001B[1;32m     53\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Get and decode as weather api\"\"\"\u001B[39;00m\n\u001B[0;32m---> 54\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get\u001B[49m\u001B[43m(\u001B[49m\u001B[43mWeatherApiResponse\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverify\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/python3.12.3/.venv/lib/python3.12/site-packages/openmeteo_requests/Client.py:35\u001B[0m, in \u001B[0;36mClient._get\u001B[0;34m(self, cls, url, params, method, verify, **kwargs)\u001B[0m\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m response\u001B[38;5;241m.\u001B[39mstatus_code \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;241m400\u001B[39m, \u001B[38;5;241m429\u001B[39m]:\n\u001B[1;32m     34\u001B[0m     response_body \u001B[38;5;241m=\u001B[39m response\u001B[38;5;241m.\u001B[39mjson()\n\u001B[0;32m---> 35\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m OpenMeteoRequestsError(response_body)\n\u001B[1;32m     37\u001B[0m response\u001B[38;5;241m.\u001B[39mraise_for_status()\n\u001B[1;32m     39\u001B[0m data \u001B[38;5;241m=\u001B[39m response\u001B[38;5;241m.\u001B[39mcontent\n",
      "\u001B[0;31mOpenMeteoRequestsError\u001B[0m: {'reason': 'Daily API request limit exceeded. Please try again tomorrow.', 'error': True}"
     ]
    }
   ],
   "execution_count": 117
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Clean the dataset\n",
    "Some of the data cleaning was preformed when we received the data from the API calls as it was deemed a more effiecent."
   ],
   "id": "bd7d948b63b5fa93"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create a single dataframe from the 2 datasets\n",
    "# Load the 2 datasets\n",
    "df1 = pd.read_csv(\"Data/Zurich.csv\")\n",
    "df2 = pd.read_csv(\"Data/Toronto.csv\")\n",
    "\n",
    "# Add a column to contains the city name\n",
    "df1['city'] = 'Zurich'\n",
    "df2['city'] = 'Toronto'"
   ],
   "id": "bdade34e064be279",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Concatenate the 2 dataframes\n",
    "df = pd.concat([df1, df2], ignore_index=True)"
   ],
   "id": "fae2e83dcbed7d85",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Identify numerical columns\n",
    "numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()"
   ],
   "id": "7898804ca335e1df",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check for empty or all zeros columns\n",
    "empty_cols = []\n",
    "for col in numerical_cols:\n",
    "\tif df[col].sum() == 0:\n",
    "\t\tempty_cols.append(col)\n",
    "\t\t\n",
    "print(empty_cols)"
   ],
   "id": "587035f9ceb038b7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Remove two columns with only zero values\n",
    "df = df.drop(empty_cols, axis=1)"
   ],
   "id": "b453b757db0f1edc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Get index of rows with NaN values\n",
    "nan_rows = df[df.isna().any(axis=1)].index.tolist()\n",
    "\n",
    "print(nan_rows)"
   ],
   "id": "65a904ec4ef376d0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df = df.drop(index=nan_rows, axis=0)",
   "id": "9c0f7f0a81a06174",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# See if the column is the correct data type\n",
    "set(df.weather_code.unique())"
   ],
   "id": "53eef2c6ac12c8ff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df['weather_code'] = df['weather_code'].astype(int)",
   "id": "1ad67d1576ab6b5d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Write cleaned dataframe to csv file to limit API calls\n",
    "df.to_csv(\"Data/clean.csv\", index = False)"
   ],
   "id": "31215bd737be924",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Check the dataset for outliers",
   "id": "dd43e5c74e37ad87"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Identify remaining numerical columns\n",
    "num_cols = df.select_dtypes(include=[np.number]).columns.tolist()"
   ],
   "id": "fc26876d5ffbc5ed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Find outliers for each column\n",
    "outlier_results = []\n",
    "\n",
    "for col in num_cols:\n",
    "    # Calculate quartiles\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    # Define outlier boundaries\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    # Find outliers\n",
    "    outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "    num_outliers = len(outliers)\n",
    "    \n",
    "    # Only inspect \n",
    "    if num_outliers > 0:\n",
    "        outlier_results.append({\n",
    "            'Column': col,\n",
    "            'Outliers Count': num_outliers,\n",
    "            'Min': df[col].min(),\n",
    "            'Q1': Q1,\n",
    "            'Median': df[col].median(),\n",
    "            'Q3': Q3,\n",
    "            'Max': df[col].max(),\n",
    "            'IQR': IQR,\n",
    "            'Lower Bound': lower_bound,\n",
    "            'Upper Bound': upper_bound\n",
    "        })\n",
    "\n",
    "# Create DataFrame with outlier results\n",
    "outlier_df = pd.DataFrame(outlier_results)\n",
    "print(\"\\nOutlier Summary:\")\n",
    "print(outlier_df)"
   ],
   "id": "dbba35fc0b9af32f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Get the variables that have the most outliers\n",
    "outlier_col = list(outlier_df[outlier_df['Outliers Count'] > 1000].Column)"
   ],
   "id": "e1af3edf6e5c764e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create box plots to inspect the top outliers\n",
    "plt.figure(figsize=(15, 10))\n",
    "df.boxplot(column=list(outlier_col), figsize=(15, 10))\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Box Plots of Numerical Columns')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "3868c1a1ff83dabd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create box plots to inspect the top outliers\n",
    "plt.figure(figsize=(15, 10))\n",
    "df.boxplot(column=['temperature_2m_min', 'apparent_temperature_min'], figsize=(15, 10))\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Box Plots of Numerical Columns')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "81bc660c7c7f6b2b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "After investagting the dataset for outliers it has become clear that the dataset does have outliers, but these outliers does fall under the expected behavior for weather patterns and in most cases represents extreme weather events, while in other cases the outliers represent weather events that don't occur frequently. For example it snowing in Zurich occurs infrequently.",
   "id": "6fb1bab74f6dead0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Working with missing data\n",
    "\n",
    "Because the data is to clean and has no missing data, I am going to create missing data and the demonstrate how to deal with missing data, by randomly removing data from the dataset"
   ],
   "id": "498cc6037f8abda"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_mis = pd.read_csv(\"Data/clean.csv\")",
   "id": "20bb0107b7fb8229",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Generate 1000 random numbers that represents the rows to apply missing values\n",
    "random_numbers = [random.randint(1, len(df_mis)) for _ in range(1000)]"
   ],
   "id": "bca5c59682172366",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Get a list of all the column names\n",
    "columns = list(df_mis.columns)\n",
    "\n",
    "# Remove date and city from the list\n",
    "columns.remove('date')\n",
    "columns.remove('city')"
   ],
   "id": "e41185059391c870",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Randomly apply NaN values to the columns and rows\n",
    "for num in random_numbers:\n",
    "\tfor col in columns:\n",
    "\t\tif random.choice([0, 1]) == 1:\n",
    "\t\t\tdf_mis.loc[num, col] = np.nan"
   ],
   "id": "b2452b6679253c6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check the extend of the missing data\n",
    "print(df_mis.isna().sum())"
   ],
   "id": "330189bf1b80586d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot a heat map for missing values\n",
    "sns.heatmap(df_mis.isnull(), cbar=True, cmap='viridis')\n",
    "plt.show()"
   ],
   "id": "a65f6f30a4c9b65e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Fill missing values with interpolation\n",
    "# Using the linear method as it is the best fit for weather data\n",
    "df_filled = df_mis[columns].interpolate(method='linear')"
   ],
   "id": "703c6021245556bb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "a821f3dbda3ab222"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check if there is still missing values\n",
    "print(df_filled.isna().sum())"
   ],
   "id": "19178164c2b7a937",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We where able to succesfully interpolate our missing values ",
   "id": "99d6f0dd33bb4f15"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Research Question 2\n",
    "##### How does Zurich and Toronto compare regarding weather seasonal attributes?\n",
    "The reason Zurich and Toronto was chosen for comparisson is because they are almost placed on the same latitude, with Zurich at 47.34621810913086°N and Toronto at 47.62741470336914°N. "
   ],
   "id": "5c05358a0f08729c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create the dataframe\n",
    "df = pd.read_csv(\"Data/clean.csv\")\n",
    "\n",
    "# Ensure datetime index\n",
    "df.index = pd.DatetimeIndex(df.date)"
   ],
   "id": "f15b11b8eca3f1b3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# Separate Zurich and Toronto data and set the date as index\n",
    "Zurich_data = df[df['city'] == 'Zurich'].set_index('date')\n",
    "Toronto_data = df[df['city'] == 'Toronto'].set_index('date')\n",
    "\n",
    "# Merge the dataframes on date\n",
    "merged_df = Zurich_data.merge(Toronto_data, on='date', suffixes=('_Zurich', '_Toronto'))\n",
    "\n",
    "# Drop redundant city columns\n",
    "merged_df = merged_df.drop(['city_Zurich', 'city_Toronto'], axis=1)\n",
    "\n",
    "# Ensure the dataframe index is of type datetime\n",
    "merged_df.index = pd.DatetimeIndex(merged_df.index)\n",
    "\n",
    "# Create a function to map months to seasons - more efficient approach\n",
    "def get_season(month):\n",
    "    if month in [12, 1, 2]:\n",
    "        return 'Winter'\n",
    "    elif month in [3, 4, 5]:\n",
    "        return 'Spring'\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 'Summer'\n",
    "    else:  # 9, 10, 11\n",
    "        return 'Fall'\n",
    "\n",
    "# Add season column more efficiently\n",
    "merged_df['season'] = merged_df.index.month.map(get_season)"
   ],
   "id": "a82689973cf3210e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Compare weather codes between cities\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Create comparison dataframe more efficiently\n",
    "Zurich_counts = merged_df['weather_code_Zurich'].value_counts().sort_index()\n",
    "Toronto_counts = merged_df['weather_code_Toronto'].value_counts().sort_index()\n",
    "\n",
    "# Combine into a single dataframe for plotting\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Zurich': Zurich_counts,\n",
    "    'Toronto': Toronto_counts\n",
    "}).reset_index().melt(\n",
    "    id_vars='index',\n",
    "    value_vars=['Zurich', 'Toronto'],\n",
    "    var_name='City',\n",
    "    value_name='Frequency'\n",
    ")\n",
    "\n",
    "# Create a cleaner bar plot\n",
    "ax = sns.barplot(x='index', y='Frequency', hue='City', data=comparison_df)\n",
    "\n",
    "# Enhance the plot with better formatting\n",
    "plt.title('Weather Code Frequency: Zurich vs. Toronto', fontsize=14)\n",
    "plt.xlabel('Weather Code', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(title='')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "985c4446e4efbf26",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The weather codes is called OWM codes\n",
    "- 0: Cloud development not observed or not observable\n",
    "- 1: Clouds generally dissolving or becoming less developed\n",
    "- 2: State of sky on the whole unchanged\n",
    "- 3: Clouds generally forming or developing\n",
    "- 51: Drizzle, not freezing, continuous, slight at time of observation\n",
    "- 53: Drizzle, not freezing, continuous, moderate at time of observation\n",
    "- 55: Drizzle, not freezing, continuous, heavy at time of observation\n",
    "- 61: Rain, not freezing, continuous, slight at time of observation\n",
    "- 63: Rain, not freezing, continuous, moderate at time of observation\n",
    "- 65: Rain, not freezing, continuous, heavy at time of observation\n",
    "- 71: Continuous fall of snowflakes, slight at time of observation\n",
    "- 73: Continuous fall of snowflakes, moderate at time of observation\n",
    "- 75: Continuous fall of snowflakes, heavy at time of observation  \n",
    "[Source](https://www.nodc.noaa.gov/archive/arc0021/0002199/1.1/data/0-data/HTML/WMO-CODE/WMO4677.HTM)\n",
    "\n",
    "By looking at the weather codes it is clear that the most common weather state for both cities is cloudy days (Code 3) "
   ],
   "id": "4800edeea9ba34b0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# Calculate seasonal means more efficiently\n",
    "# Define the season order for consistent presentation\n",
    "season_order = ['Winter', 'Spring', 'Summer', 'Fall']\n",
    "\n",
    "# Get seasonal averages, excluding weather code columns\n",
    "season_stats = merged_df.drop(['weather_code_Zurich', 'weather_code_Toronto'], axis=1).groupby('season').mean()\n",
    "\n",
    "# Reorder seasons for better visualization\n",
    "season_stats = season_stats.reindex(season_order)\n",
    "\n",
    "# Create a more comprehensive temperature comparison visualization\n",
    "# Extract only temperature columns for cleaner analysis\n",
    "temp_columns = [\n",
    "    'temperature_2m_mean_Zurich', 'temperature_2m_mean_Toronto',\n",
    "    'apparent_temperature_mean_Zurich', 'apparent_temperature_mean_Toronto'\n",
    "]\n",
    "\n",
    "# Create a dataframe in tidy format for seaborn plotting\n",
    "temp_data = []\n",
    "for column in temp_columns:\n",
    "    city = 'Zurich' if 'Zurich' in column else 'Toronto'\n",
    "    temp_type = 'Air' if 'temperature_2m' in column else 'Apparent'\n",
    "    \n",
    "    for season in season_order:\n",
    "        temp_value = season_stats.loc[season, column]\n",
    "        temp_data.append({\n",
    "            'Season': season,\n",
    "            'City': city,\n",
    "            'Type': temp_type,\n",
    "            'Temperature': temp_value\n",
    "        })\n",
    "\n",
    "temp_df = pd.DataFrame(temp_data)"
   ],
   "id": "35f97aa40bae885a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Actual vs Apparent Temperature vs Seasonly Comparison ",
   "id": "3f195459293ed5d9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# Create a more informative and visually appealing temperature comparison\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Add a column combining city and temperature type for better visualization\n",
    "temp_df['City_Type'] = temp_df['City'] + ' (' + temp_df['Type'] + ')'\n",
    "\n",
    "# Define a better color palette\n",
    "custom_palette = {\n",
    "    'Zurich (Air)': '#1f77b4',      # Darker blue\n",
    "    'Zurich (Apparent)': '#aec7e8',  # Lighter blue\n",
    "    'Toronto (Air)': '#ff7f0e',      # Darker orange\n",
    "    'Toronto (Apparent)': '#ffbb78'  # Lighter orange\n",
    "}\n",
    "\n",
    "# Create an enhanced bar plot\n",
    "sns.barplot(\n",
    "    data=temp_df,\n",
    "    x='Season',\n",
    "    y='Temperature',\n",
    "    hue='City_Type',\n",
    "    palette=custom_palette\n",
    ")\n",
    "\n",
    "# Add plot details for better clarity\n",
    "plt.title('Temperature Comparison: Zurich vs. Toronto by Season', fontsize=16)\n",
    "plt.xlabel('Season', fontsize=14)\n",
    "plt.ylabel('Temperature (°C)', fontsize=14)\n",
    "plt.legend(title='City & Temperature Type', fontsize=12)\n",
    "\n",
    "# Remove unnecessary chart elements\n",
    "sns.despine(left=True, bottom=True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "4e366393872e23c0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Apparent Temperature refers to how hot or cold the air feels to the human body, rather than the actual air temperature measured by a thermometer. It combines the effects of several environmental factors such air temperature, humitidy and wind speed.\n",
    "\n",
    "We can see from the bar chart that Zürich and Toronto enjoy simailar temperatures during summer, with small differences between air and apparent temperatures. Toronto has milder air temperatures during spring and fall than Zürich and for both cities we can see envorimental factors having a bigger impact on apparent temperatures. While Toronto is slight colder than Zürich during the winter months it is clear that enviromental factors have a substansially larger impact on apparent temperatures than during other seasons."
   ],
   "id": "ffcc464090dc5c0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Daylight vs Sunshine Ratio",
   "id": "e2bda44cc10402fa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Extract month from the datetime index\n",
    "merged_df['month'] = merged_df.index.month\n",
    "\n",
    "# Create month names for better readability\n",
    "month_names = {1: 'Jan', 2: 'Feb', 3: 'Mar', 4: 'Apr', 5: 'May', 6: 'Jun', \n",
    "               7: 'Jul', 8: 'Aug', 9: 'Sep', 10: 'Oct', 11: 'Nov', 12: 'Dec'}\n",
    "merged_df['month_name'] = merged_df['month'].map(month_names)\n",
    "\n",
    "# Calculate sunshine ratio for both cities\n",
    "merged_df['sunshine_ratio_Zurich'] = merged_df['sunshine_duration_Zurich'] / merged_df['daylight_duration_Zurich']\n",
    "merged_df['sunshine_ratio_Toronto'] = merged_df['sunshine_duration_Toronto'] / merged_df['daylight_duration_Toronto']\n",
    "\n",
    "# Group by month and calculate average sunshine ratio for each month\n",
    "monthly_sunshine = merged_df.groupby('month_name').agg({\n",
    "    'sunshine_ratio_Zurich': 'mean',\n",
    "    'sunshine_ratio_Toronto': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# Sort by month\n",
    "month_order = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "monthly_sunshine['month_name'] = pd.Categorical(monthly_sunshine['month_name'], categories=month_order, ordered=True)\n",
    "monthly_sunshine = monthly_sunshine.sort_values('month_name')"
   ],
   "id": "3e2a87b1bfed40d1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Reshape data\n",
    "sunshine_melted = pd.melt(monthly_sunshine, \n",
    "                          id_vars=['month_name'],\n",
    "                          value_vars=['sunshine_ratio_Zurich', 'sunshine_ratio_Toronto'],\n",
    "                          var_name='city', \n",
    "                          value_name='sunshine_ratio')\n",
    "\n",
    "# Clean up city names for legend\n",
    "sunshine_melted['city'] = sunshine_melted['city'].map({\n",
    "    'sunshine_ratio_Zurich': 'Zurich',\n",
    "    'sunshine_ratio_Toronto': 'Toronto'\n",
    "})"
   ],
   "id": "1a8c6e7a719418b8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create bar plot\n",
    "plt.figure(figsize=(14, 7))\n",
    "ax = sns.barplot(x='month_name', y='sunshine_ratio', hue='city', data=sunshine_melted)\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Monthly Sunshine Ratio (Actual Sunshine / Total Daylight)', fontsize=16)\n",
    "plt.xlabel('Month', fontsize=14)\n",
    "plt.ylabel('Sunshine Ratio', fontsize=14)\n",
    "plt.ylim(0, 1.0)  # Set y-axis from 0 to 1 (0-100%)\n",
    "\n",
    "# Format y-axis as percentage\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "ax.yaxis.set_major_formatter(PercentFormatter(1.0))\n",
    "\n",
    "# Add annotations for each bar to show the exact percentage\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    ax.annotate(f'{height:.1%}',\n",
    "                (p.get_x() + p.get_width() / 2., height),\n",
    "                ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.legend(title='City', fontsize=12)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate annual averages\n",
    "annual_avg = merged_df.agg({\n",
    "    'sunshine_ratio_Zurich': 'mean',\n",
    "    'sunshine_ratio_Toronto': 'mean'\n",
    "})\n",
    "\n",
    "print(f\"Annual average sunshine ratio for Zurich: {annual_avg['sunshine_ratio_Zurich']:.2%}\")\n",
    "print(f\"Annual average sunshine ratio for Toronto: {annual_avg['sunshine_ratio_Toronto']:.2%}\")"
   ],
   "id": "e24b6137313099e3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "4dc394e359a13382",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
